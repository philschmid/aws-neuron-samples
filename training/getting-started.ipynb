{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/optimum-neuron.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30753db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.26.1\n",
      "- Platform: Linux-5.15.0-1030-aws-x86_64-with-glibc2.29\n",
      "- Python version: 3.8.10\n",
      "- Huggingface_hub version: 0.12.1\n",
      "- PyTorch version (GPU?): 1.13.1+cu117 (False)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1678a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance-type: trn1.2xlarge\n",
      "instance-id: i-0570615e41700a481\n",
      "+--------+--------+--------+---------+\n",
      "| NEURON | NEURON | NEURON |   PCI   |\n",
      "| DEVICE | CORES  | MEMORY |   BDF   |\n",
      "+--------+--------+--------+---------+\n",
      "| 0      | 2      | 32 GB  | 00:1e.0 |\n",
      "+--------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "!neuron-ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17851024",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358933de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 130.36it/s]\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c/cache-084cb9babe899b20.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c/cache-5f7f794fe0ef7b57.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10003\n",
      "Test dataset size: 3080\n",
      "{'text': 'Can I change my address?', 'label': 30}\n",
      "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset id from huggingface.co/dataset\n",
    "dataset_id = \"banking77\"\n",
    "# Model id to load the tokenizer\n",
    "model_id = \"bert-base-uncased\"\n",
    "save_dataset_path = \"dataset\"\n",
    "\n",
    "\n",
    "# Load raw dataset\n",
    "raw_dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(raw_dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(raw_dataset['test'])}\")\n",
    "\n",
    "# Train dataset size: 10003\n",
    "# Test dataset size: 3080\n",
    "from random import randrange\n",
    "\n",
    "random_id = randrange(len(raw_dataset['train']))\n",
    "print(raw_dataset['train'][random_id])\n",
    "# {'text': 'How can I change my PIN without going to the bank?', 'label': 21}\n",
    "\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Tokenize helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize dataset\n",
    "raw_dataset =  raw_dataset.rename_column(\"label\", \"labels\") # to match Trainer\n",
    "tokenized_dataset = raw_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "print(tokenized_dataset[\"train\"].features.keys())\n",
    "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask','lable'])\n",
    "# save dataset to disk\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(save_dataset_path,\"train\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(save_dataset_path,\"eval\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3d70d49",
   "metadata": {},
   "source": [
    "## precompiple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767b3283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-13 09:13:26.000335: INFO ||PARALLEL_COMPILE||: Removing existing workdir /tmp/parallel_compile_workdir\n",
      "2023-03-13 09:13:26.000363: INFO ||PARALLEL_COMPILE||: Running trial run (add option to terminate trial run early; also ignore trial run's generated outputs, i.e. loss, checkpoints)\n",
      "is precompilation: 1\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n",
      "  Number of trainable parameters = 335220813\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]2023-03-13 09:13:48.000872: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.398_16500088451374625205.hlo.pb \n",
      "2023-03-13 09:13:48.000878: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-13 09:13:48.000887: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16500088451374625205/MODULE_SyncTensorsGraph.398_16500088451374625205/d0c928c7-f0e5-448f-aa12-bb0b3c9f26ed/MODULE_SyncTensorsGraph.398_16500088451374625205.neff. Exiting with a successfully compiled graph\n",
      "  5%|â–Œ         | 1/20 [00:00<00:07,  2.45it/s]2023-03-13 09:13:51.000163: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb \n",
      "2023-03-13 09:13:51.000178: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/3643ee85-d268-4110-9b6f-3334f79e456c/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000178: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/4ba6a9ec-e217-432b-9289-25789e48e9d3/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000179: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/c4e9face-567b-43a0-89b3-bd6543a107fa/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000179: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/45880d66-81b4-4498-ae74-7858129fcda4/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000180: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/edc10670-4e62-44f2-b5b9-42df3ae4b2b6/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000180: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/c4f8cdff-e12c-4498-934d-aafc1f3d27c2/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000180: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/9040b2a7-72e3-45b0-bb8e-3993ef0b52c2/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000180: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-13 09:13:51.000193: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-13 09:13:51.000205: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_1_SyncTensorsGraph.41359_12643167559187961032_ip-172-31-79-164-6e4c064d-12169-5f64f13cdd0a8/554846e9-7d9a-4799-ade9-eb576d9e31e3/MODULE_1_SyncTensorsGraph.41359_12643167559187961032_ip-172-31-79-164-6e4c064d-12169-5f64f13cdd0a8.neff. Continuing with search.\n",
      "2023-03-13 09:13:51.000205: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-13 09:13:51.000209: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/d7b3d81a-7459-4c85-bd47-458a09804573\n",
      "2023-03-13 09:13:51.000257: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 10%|â–ˆ         | 2/20 [00:05<00:51,  2.88s/it]2023-03-13 09:13:55.000947: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb \n",
      "2023-03-13 09:13:55.000959: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/458630af-6078-44c5-9f78-be6a11204178/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000959: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/b18a241b-f191-4fdd-a61b-4faf146e9e76/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000959: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/a55587ca-74ec-45c2-a363-cbbdc359bfa4/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000960: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/5a1dd09e-1573-46ba-842f-e3f7a1c29548/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000960: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/3f5ed472-c6a7-424e-bf1e-37a2ef1843fb/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000961: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/3cf69bdf-32cb-4320-a9f4-89dd0354e5ea/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000961: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/c34b0875-19ab-4093-92ad-5ba7d455c156/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-13 09:13:55.000961: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-13 09:13:55.000967: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/4593fea0-2cf6-4d17-9ef8-3668c1273af1\n",
      "2023-03-13 09:13:55.000972: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:11<00:02,  3.04it/s]2023-03-13 09:14:02.000456: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_12626849408468488449.hlo.pb \n",
      "2023-03-13 09:14:02.000592: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12626849408468488449/MODULE_SyncTensorsGraph.41359_12626849408468488449/30a0f8bb-6a4a-4d31-9455-4bee91142c6c/MODULE_SyncTensorsGraph.41359_12626849408468488449.neff. Exiting with a successfully compiled graph\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:18<00:00,  4.14it/s]***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n",
      "2023-03-13 09:14:07.000268: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.8831_6359244636338052065.hlo.pb \n",
      "2023-03-13 09:14:07.000328: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6359244636338052065/MODULE_SyncTensorsGraph.8831_6359244636338052065/9eb4a6a8-5bef-4d24-920a-9c232c447f1d/MODULE_SyncTensorsGraph.8831_6359244636338052065.neff. Exiting with a successfully compiled graph\n",
      "2023-03-13 09:14:07.000560: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_1002868706066901398.hlo.pb \n",
      "2023-03-13 09:14:07.000564: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_SyncTensorsGraph.4_1002868706066901398/8121fb1e-f175-4f7a-baaa-14a326a19083/MODULE_SyncTensorsGraph.4_1002868706066901398.neff. Exiting with a successfully compiled graph\n",
      "2023-03-13 09:14:07.000633: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_14019065114978382472.hlo.pb \n",
      "2023-03-13 09:14:07.000637: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_SyncTensorsGraph.4_14019065114978382472/5d49a674-a046-424b-9e79-b5d4db41e0d1/MODULE_SyncTensorsGraph.4_14019065114978382472.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:00<00:00, 37.35it/s]\u001b[A\n",
      "                                               [A\n",
      "\u001b[A{'eval_loss': 0.0, 'eval_f1': 0.0, 'eval_runtime': 1.1625, 'eval_samples_per_second': 8.602, 'eval_steps_per_second': 1.72, 'epoch': 1.0}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:19<00:00,  4.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 31.54it/s]\u001b[A\n",
      "                                               \u001b[ASaving model checkpoint to run1/checkpoint-20\n",
      "Configuration saved in run1/checkpoint-20/config.json\n",
      "Model weights saved in run1/checkpoint-20/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from run1/checkpoint-20 (score: 0.0).\n",
      "{'train_runtime': 56.7647, 'train_samples_per_second': 0.352, 'train_steps_per_second': 0.352, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:56<00:00,  2.84s/it]\n",
      "tokenizer config file saved in run1/tokenizer_config.json\n",
      "Special tokens file saved in run1/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'dataset': {'name': 'banking77', 'type': 'banking77', 'config': 'default', 'split': 'test', 'args': 'default'}}\n",
      "2023-03-13 09:14:47.000481: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs\n",
      "2023-03-13 09:14:47.000483: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff\n",
      "2023-03-13 09:14:47.000484: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff\n",
      "..................................................................Killed\n",
      "2023-03-13 09:25:40.000980: ERROR ||PARALLEL_COMPILE||: parallel compilation with neuronx-cc exited with error.Received error code: 137\n",
      "..................^C\n"
     ]
    }
   ],
   "source": [
    "!neuron_parallel_compile python3 scripts/train.py --model_id bert-large-uncased --per_device_train_batch_size 8 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01bff4e",
   "metadata": {},
   "source": [
    "`2023-03-13 08:24:52.000851: ERROR ||PARALLEL_COMPILE||: parallel compilation with neuronx-cc exited with error.Received error code: 137`\n",
    "\n",
    "=> OOM? but training with BS 8 works. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "280aa609",
   "metadata": {},
   "source": [
    "```\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total graphs: 2\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total successful compilations: 0\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total failed compilations: 2\n",
    "```\n",
    "\n",
    "monitoring `htop` has shown that we ran out of CPU Memory -> (30.8GB)\n",
    "\n",
    "`free -h`\n",
    "\n",
    "shows no swap \n",
    "\n",
    "\n",
    "```bash\n",
    "# add swap 10GB of swap\n",
    "sudo fallocate -l 20G /swapfile\n",
    "# change permissions\n",
    "sudo chmod 600 /swapfile\n",
    "# mark the file as swap space\n",
    "sudo mkswap /swapfile\n",
    "# enable swap \n",
    "sudo swapon /swapfile\n",
    "# make swap file permanent\n",
    "# echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab\n",
    "```\n",
    "\n",
    "20 GB was not enough! ðŸ¤¯\n",
    "\n",
    "\n",
    "![img](./im.png)\n",
    "\n",
    "switch swap: https://askubuntu.com/questions/1264568/increase-swap-in-20-04"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8dc0746",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae31815",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/train.py --model_id bert-large-uncased --per_device_train_batch_size 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b757305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
